{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4914104/\n",
    "    За основу взята данная архитектура: сворачивание входных данных, затем bilstm.\n",
    "    \n",
    "    В качестве входных данных использовались one-hot последовательности длинной от 5 до 30 символов и предсказывался следующий символ, те бралась только информация слева."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(test 0.42)`\n",
    "`(эпох 160, батч 200)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import LSTM, Bidirectional, Conv1D, MaxPool1D \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "curruser = os.environ.get('USER')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "from PreprocInput import preproc_\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pylab import rcParams\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 12, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with K.tf.device('/GPU:0'):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "    session = tf.Session(config=config)\n",
    "    K.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    plt.plot(history['acc'])\n",
    "    plt.plot(history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_heatmap(y_true, y_pred):\n",
    "    '''\n",
    "    Построение Confusion matrix (матрицы ошибок)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test: pandas.Series, numpy.array\n",
    "        Целевая для обучающего набора\n",
    "    y_pred: pandas.Series, numpy.array\n",
    "        Значения целевой переменной, предсказанные классификатором\n",
    "    '''\n",
    "    rcParams['figure.figsize'] = 6, 4\n",
    "    sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='d', cmap='Greens')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset and preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ACGGCTGGAGCCCATGTTCAGCATGAAAAC</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TAAATTTCTGGATGGCAATGAAATGACATT</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>TCCACTTGGCAGCCAAATATGGCCAGACAA</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CGGAGGAGAGCACCGAGCCCCTGAGTGAGG</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>GGACCACATTTGGGGAGCTTGCCATTTTAT</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              seq label\n",
       "0  ACGGCTGGAGCCCATGTTCAGCATGAAAAC     A\n",
       "1  TAAATTTCTGGATGGCAATGAAATGACATT     A\n",
       "2  TCCACTTGGCAGCCAAATATGGCCAGACAA     A\n",
       "3  CGGAGGAGAGCACCGAGCCCCTGAGTGAGG     A\n",
       "4  GGACCACATTTGGGGAGCTTGCCATTTTAT     A"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/LeftWrap_5to30.csv', sep=';')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3351352, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'A', 1: 'C', 2: 'G', 3: 'T'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(data.label.values)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "indices_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3351352, 30, 4), (3351352, 4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAXSEQLEN = max(map(len, data.seq.values))\n",
    "\n",
    "X_data, y_data = preproc_.get_input_array(data.seq.values, data.label.values, MAXSEQLEN , chars, char_indices)\n",
    "X_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train model: CNN+BILSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ruser7/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 25, 120)           3000      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 6, 120)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6, 120)            480       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 120)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 6, 256)            254976    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                98368     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 357,084\n",
      "Trainable params: 356,844\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def danq_model(seq_length, vocab_size):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(input_shape=(seq_length, vocab_size),\n",
    "                        kernel_size=6,\n",
    "                        filters=120,\n",
    "                        padding=\"valid\",\n",
    "                        activation=\"tanh\"))\n",
    "\n",
    "    model.add(MaxPool1D(pool_size=4, strides=4))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = danq_model(MAXSEQLEN, len(chars))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2144864 samples, validate on 536217 samples\n",
      "Epoch 1/160\n",
      "2144864/2144864 [==============================] - 413s 193us/step - loss: 1.3486 - acc: 0.3282 - val_loss: 1.3373 - val_acc: 0.3395\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.33729, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 2/160\n",
      "2144864/2144864 [==============================] - 408s 190us/step - loss: 1.3347 - acc: 0.3408 - val_loss: 1.3267 - val_acc: 0.3487\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.33729 to 1.32672, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 3/160\n",
      "2144864/2144864 [==============================] - 407s 190us/step - loss: 1.3271 - acc: 0.3480 - val_loss: 1.3199 - val_acc: 0.3535\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.32672 to 1.31990, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 4/160\n",
      "2144864/2144864 [==============================] - 406s 189us/step - loss: 1.3214 - acc: 0.3533 - val_loss: 1.3134 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.31990 to 1.31343, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 5/160\n",
      "2144864/2144864 [==============================] - 407s 190us/step - loss: 1.3170 - acc: 0.3575 - val_loss: 1.3091 - val_acc: 0.3638\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.31343 to 1.30912, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 6/160\n",
      "2144864/2144864 [==============================] - 405s 189us/step - loss: 1.3128 - acc: 0.3616 - val_loss: 1.3060 - val_acc: 0.3676\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.30912 to 1.30599, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 7/160\n",
      "2144864/2144864 [==============================] - 407s 190us/step - loss: 1.3087 - acc: 0.3660 - val_loss: 1.3026 - val_acc: 0.3705\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.30599 to 1.30262, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 8/160\n",
      "2144864/2144864 [==============================] - 406s 189us/step - loss: 1.3054 - acc: 0.3695 - val_loss: 1.2983 - val_acc: 0.3741\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.30262 to 1.29831, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 9/160\n",
      "2144864/2144864 [==============================] - 407s 190us/step - loss: 1.3025 - acc: 0.3726 - val_loss: 1.2957 - val_acc: 0.3774\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.29831 to 1.29569, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 10/160\n",
      "2144864/2144864 [==============================] - 407s 190us/step - loss: 1.2993 - acc: 0.3756 - val_loss: 1.2955 - val_acc: 0.3756\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.29569 to 1.29552, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 11/160\n",
      "2144864/2144864 [==============================] - 406s 189us/step - loss: 1.2965 - acc: 0.3788 - val_loss: 1.2902 - val_acc: 0.3818\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.29552 to 1.29020, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 12/160\n",
      "2144864/2144864 [==============================] - 406s 189us/step - loss: 1.2939 - acc: 0.3811 - val_loss: 1.2884 - val_acc: 0.3850\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.29020 to 1.28838, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 13/160\n",
      "2144864/2144864 [==============================] - 407s 190us/step - loss: 1.2915 - acc: 0.3835 - val_loss: 1.2853 - val_acc: 0.3866\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.28838 to 1.28535, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 14/160\n",
      "2144864/2144864 [==============================] - 406s 189us/step - loss: 1.2890 - acc: 0.3859 - val_loss: 1.2844 - val_acc: 0.3892\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.28535 to 1.28436, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 15/160\n",
      "2144864/2144864 [==============================] - 406s 189us/step - loss: 1.2873 - acc: 0.3877 - val_loss: 1.2839 - val_acc: 0.3879\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.28436 to 1.28386, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 16/160\n",
      "2144864/2144864 [==============================] - 405s 189us/step - loss: 1.2855 - acc: 0.3895 - val_loss: 1.2802 - val_acc: 0.3927\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.28386 to 1.28016, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 17/160\n",
      "2144864/2144864 [==============================] - 407s 190us/step - loss: 1.2839 - acc: 0.3907 - val_loss: 1.2785 - val_acc: 0.3945\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.28016 to 1.27853, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 18/160\n",
      "2144864/2144864 [==============================] - 406s 189us/step - loss: 1.2824 - acc: 0.3925 - val_loss: 1.2765 - val_acc: 0.3950\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.27853 to 1.27653, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 19/160\n",
      "2144864/2144864 [==============================] - 407s 190us/step - loss: 1.2807 - acc: 0.3940 - val_loss: 1.2784 - val_acc: 0.3941\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.27653\n",
      "Epoch 20/160\n",
      "2144864/2144864 [==============================] - 408s 190us/step - loss: 1.2795 - acc: 0.3955 - val_loss: 1.2762 - val_acc: 0.3964\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.27653 to 1.27618, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 21/160\n",
      "2144864/2144864 [==============================] - 407s 190us/step - loss: 1.2781 - acc: 0.3965 - val_loss: 1.2725 - val_acc: 0.3990\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.27618 to 1.27245, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 22/160\n",
      "2144864/2144864 [==============================] - 397s 185us/step - loss: 1.2770 - acc: 0.3977 - val_loss: 1.2721 - val_acc: 0.4005\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.27245 to 1.27213, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 23/160\n",
      "2144864/2144864 [==============================] - 381s 178us/step - loss: 1.2759 - acc: 0.3989 - val_loss: 1.2733 - val_acc: 0.3991\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.27213\n",
      "Epoch 24/160\n",
      "2144864/2144864 [==============================] - 394s 183us/step - loss: 1.2751 - acc: 0.3996 - val_loss: 1.2736 - val_acc: 0.3996\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.27213\n",
      "Epoch 25/160\n",
      "2144864/2144864 [==============================] - 374s 175us/step - loss: 1.2742 - acc: 0.4003 - val_loss: 1.2737 - val_acc: 0.3986\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.27213\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 26/160\n",
      "2144864/2144864 [==============================] - 388s 181us/step - loss: 1.2640 - acc: 0.4096 - val_loss: 1.2636 - val_acc: 0.4078\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.27213 to 1.26361, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 27/160\n",
      "2144864/2144864 [==============================] - 382s 178us/step - loss: 1.2615 - acc: 0.4114 - val_loss: 1.2624 - val_acc: 0.4088\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.26361 to 1.26237, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 28/160\n",
      "2144864/2144864 [==============================] - 377s 176us/step - loss: 1.2603 - acc: 0.4122 - val_loss: 1.2616 - val_acc: 0.4095\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.26237 to 1.26165, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 29/160\n",
      "2144864/2144864 [==============================] - 372s 173us/step - loss: 1.2596 - acc: 0.4131 - val_loss: 1.2610 - val_acc: 0.4104\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.26165 to 1.26099, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 30/160\n",
      "2144864/2144864 [==============================] - 369s 172us/step - loss: 1.2589 - acc: 0.4139 - val_loss: 1.2604 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.26099 to 1.26040, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 31/160\n",
      "2144864/2144864 [==============================] - 368s 171us/step - loss: 1.2584 - acc: 0.4139 - val_loss: 1.2599 - val_acc: 0.4109\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.26040 to 1.25993, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 32/160\n",
      "2144864/2144864 [==============================] - 368s 172us/step - loss: 1.2576 - acc: 0.4146 - val_loss: 1.2597 - val_acc: 0.4111\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.25993 to 1.25974, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 33/160\n",
      "2144864/2144864 [==============================] - 369s 172us/step - loss: 1.2570 - acc: 0.4153 - val_loss: 1.2591 - val_acc: 0.4118\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.25974 to 1.25912, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 34/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2144864/2144864 [==============================] - 367s 171us/step - loss: 1.2566 - acc: 0.4155 - val_loss: 1.2585 - val_acc: 0.4123\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.25912 to 1.25847, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 35/160\n",
      "2144864/2144864 [==============================] - 369s 172us/step - loss: 1.2567 - acc: 0.4157 - val_loss: 1.2584 - val_acc: 0.4126\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.25847 to 1.25842, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 36/160\n",
      "2144864/2144864 [==============================] - 367s 171us/step - loss: 1.2561 - acc: 0.4162 - val_loss: 1.2581 - val_acc: 0.4130\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.25842 to 1.25809, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 37/160\n",
      "2144864/2144864 [==============================] - 366s 171us/step - loss: 1.2556 - acc: 0.4165 - val_loss: 1.2580 - val_acc: 0.4129\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.25809 to 1.25803, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 38/160\n",
      "2144864/2144864 [==============================] - 366s 171us/step - loss: 1.2555 - acc: 0.4167 - val_loss: 1.2573 - val_acc: 0.4130\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.25803 to 1.25735, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 39/160\n",
      "2144864/2144864 [==============================] - 373s 174us/step - loss: 1.2549 - acc: 0.4171 - val_loss: 1.2570 - val_acc: 0.4134\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.25735 to 1.25703, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 40/160\n",
      "2144864/2144864 [==============================] - 367s 171us/step - loss: 1.2551 - acc: 0.4167 - val_loss: 1.2567 - val_acc: 0.4136\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.25703 to 1.25671, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 41/160\n",
      "2144864/2144864 [==============================] - 366s 171us/step - loss: 1.2546 - acc: 0.4172 - val_loss: 1.2567 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.25671 to 1.25668, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 42/160\n",
      "2144864/2144864 [==============================] - 366s 170us/step - loss: 1.2543 - acc: 0.4176 - val_loss: 1.2564 - val_acc: 0.4143\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.25668 to 1.25636, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 43/160\n",
      "2144864/2144864 [==============================] - 372s 174us/step - loss: 1.2541 - acc: 0.4179 - val_loss: 1.2562 - val_acc: 0.4144\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.25636 to 1.25620, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 44/160\n",
      "2144864/2144864 [==============================] - 375s 175us/step - loss: 1.2536 - acc: 0.4183 - val_loss: 1.2558 - val_acc: 0.4142\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.25620 to 1.25576, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 45/160\n",
      "2144864/2144864 [==============================] - 374s 174us/step - loss: 1.2535 - acc: 0.4182 - val_loss: 1.2559 - val_acc: 0.4141\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.25576\n",
      "Epoch 46/160\n",
      "2144864/2144864 [==============================] - 373s 174us/step - loss: 1.2535 - acc: 0.4184 - val_loss: 1.2560 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.25576\n",
      "Epoch 47/160\n",
      "2144864/2144864 [==============================] - 374s 174us/step - loss: 1.2532 - acc: 0.4185 - val_loss: 1.2552 - val_acc: 0.4149\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.25576 to 1.25523, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 48/160\n",
      "2144864/2144864 [==============================] - 374s 175us/step - loss: 1.2528 - acc: 0.4187 - val_loss: 1.2552 - val_acc: 0.4147\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.25523 to 1.25519, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 49/160\n",
      "2144864/2144864 [==============================] - 374s 174us/step - loss: 1.2525 - acc: 0.4197 - val_loss: 1.2549 - val_acc: 0.4150\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.25519 to 1.25493, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 50/160\n",
      "2144864/2144864 [==============================] - 362s 169us/step - loss: 1.2525 - acc: 0.4193 - val_loss: 1.2550 - val_acc: 0.4156\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.25493\n",
      "Epoch 51/160\n",
      "2144864/2144864 [==============================] - 367s 171us/step - loss: 1.2525 - acc: 0.4188 - val_loss: 1.2545 - val_acc: 0.4157\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.25493 to 1.25454, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 52/160\n",
      "2144864/2144864 [==============================] - 388s 181us/step - loss: 1.2521 - acc: 0.4193 - val_loss: 1.2545 - val_acc: 0.4158\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.25454 to 1.25448, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 53/160\n",
      "2144864/2144864 [==============================] - 370s 173us/step - loss: 1.2517 - acc: 0.4202 - val_loss: 1.2542 - val_acc: 0.4159\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.25448 to 1.25417, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 54/160\n",
      "2144864/2144864 [==============================] - 367s 171us/step - loss: 1.2517 - acc: 0.4202 - val_loss: 1.2541 - val_acc: 0.4159\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.25417 to 1.25407, saving model to ./same_/danq_hybrid.h5\n",
      "Epoch 55/160\n",
      " 541800/2144864 [======>.......................] - ETA: 4:16 - loss: 1.2512 - acc: 0.4204"
     ]
    }
   ],
   "source": [
    "path = './same_/danq_hybrid.h5'\n",
    "\n",
    "callbacks = [EarlyStopping(patience=10, monitor='val_loss'),\n",
    "                 ModelCheckpoint(path, monitor='val_loss', verbose=1, save_best_only=True),\n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)]\n",
    "\n",
    "BATCH_SIZE=200\n",
    "n_epoch=160\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=n_epoch, shuffle=True,\n",
    "                     validation_split=0.2, verbose=1, callbacks=callbacks).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOB validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.argmax(axis=-1)\n",
    "\n",
    "y_true = y_test.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaUAAAEgCAYAAAAUr2zFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeZzM9R/A8dfssGsP5zpyX/EhlHuR++jWRVRIFyGKiERuypGzklBIQiqqH8pdue+cnxDltqxrF3vMzu+P7+yaHTNrx3xnd/F+esxjZr/fz7zn8x0z3/d8Pt/P9/O12O12hBBCiMwgIKMrIIQQQiSRpCSEECLTkKQkhBAi05CkJIQQItOQpCSEECLTkKQkhBAi05CkJIQQItOQpCSEECLTyJLRFbjNKGCe09+lgAHAcWAQUB6oCWxxrG8DvOtU/n6gKrADqAbMAIKBxcDbQNKZzN2ANwEb8D+gt9kb4iulVFFgFlAAo95faK0nONalqL/WurfT84oBe4FBWusxTsutGO/bca31E45lFmAY8Jwj1mSt9cR02DyveHovlFKVgc+BbEAC0EVrvcnpeTWA9cDzWusFTstzYLxHC7XWXR3LAoFPgIZAItBPa/19OmzeLXH9/1RKlQTmAuHAVqCd1jrO8XmYCeQCrMB7WuvFSqmawBeOcBaMz8uPjti5gGlARYz3+1Wt9fp03DzhR5kiKSmlCgCVgUIYO+mrwAlgp9b6VEbWzYXGqCcYX6DjwI9ACPAsMMWl/DeOG0AlYCFGQgKYDHQANmIkpUeAJUAj4CngASAWyO+H7TBDAtBTa71NKZUd2KqUWoaxY34KeEBrHauUcq3/WIztdPU2sA/I4bTsZaAoUE5rnegmVmbh6b0YBQzWWi9RSj3m+LshJO+0RwK/uYk3FPjdZVk/4IzWuqxSKgDI459NMY3r/+dIYJzWeq5S6nPgNYzvQH9gvtZ6slLqPozvQglgN1Bda52glCoI7FRK/ay1TgAmAEu11i0dyTokXbdM+FWGJiWlVATGh7Uuxq8hi0sRu1LqT6CP1npDetfvJpoAh4B/01j+BYxfigAFMb6sSds0C3gaY2fdGfgIIyEBnDGjsmbTWp8ETjoeX1ZK7QMKYyTaj7TWsY51yfVXSj0NHAZinGMppYoAjwPDgXecVnUGXtRaJ7rGykxSeS/sXN8p58T4oZWkG/A9UMM5llKqGkZiXwpUd1r1KlDO8RqJwFnTN8Qkrv+fjhZvY+BFR5GZGD0Lk/HwHmmtrziFzOYoh1IqJ1Af4wcLWus4IM5vGyPSXYYdU1JKNcb4NVgY49dSM6ACUNpx3xT4AGMHvlop1SiDqurJ88C3XpRv7VS+MHDMad0xxzKAskA9jBbUGlx2WpmRUqoEUAWjzmWBekqpjUqpNY4uKpRSYUAfYLCbEOMxuigTXZaXBlorpbYopZYopcr4axvM4vJedAdGK6WOAmOAvo4yhYFnMHbKzs8NAD4Gerksz+V4OFQptU0p9Z2jdyGzcv3/DAcuOFo5kPLzPghoq5Q6htFK6pYURCkVoZTaA+wCOjmeXxKIBL5SSm1XSk1TSoX6e4NE+snIgQ7Dgc1ARa31R1rrlVrrfVrrw477lVrrERjdXluBDzOwrq4CgSeB79JYPgK4gtElcTNZMLpmamEcj5rPjS3ITMORbL4HumutL+Gm/o5fyoMwum+iXZ7/BEa31FY34YOAa1rr6sBU4Eu/bYgJ3LwXnYEeWuuiQA9guqPoeIzWv2sS7gIs1lofc1meBSgCrNNaV8U4DjWGTOgm/5/uvADM0FoXAR4DvnYkZ7TWG7XWFTB+mPVVSmXDeC+qYhxfrILR6n7P7O0QGceSUbOEK6WuAG9praeloWwHYILW+pb6jgPfqWzqRjav0JBOdVvz+JTOKZYv6zKNPj+NZduxvSmWj36qF2ejzzNyhbFPuid7XpZ1mUqlkc8A0LrKI9S/tzpvfjeMnzt+ypiVX7HmoDFWYt/7P1NvwkucjTnvc73PjVztcwxnCfEJdH/zHWo9WIu27Y2emW5vvE3719pRvabR8/TUI88yY8503u3eh9OnjN63y5cvE2AJ4I2uHYk8fYbFvyzBas1CXGws0TExNG7SiKEjB9OieSsmTh5P4SKFsNvtNKzdhDUbVppS9/hEc3t8EuIT6NWtNxF1avLCS88D0LTOIyxbuwSLxYLdbqdpnUdYsf5Xnn2kFXbHmJaL5y+SLVsQfQa+y8rfVrNz204sAQFcvXKV+Ph4WrR+hs5vv0HjiIdYseFXAgICOH3qND0692LOj1+bUvfNkRtNiQPw07TFbF62Fas1gPi4BK5ducb9dSuyf7Nm2IKBWK1WDu85wpJZv9FlZEdGvDqazh91IHd+ozE4uO0I3pnUjey5s6eIO6nnZJ7q+AS58uVkbNdJDJrTD4BDf/3Dsrkr6TTiddO24eEizX36EWhpViTN+xv7smOZ9gdnRsnIY0rnMbpn0qK0o3ym0LrqI8zbtjRNZS0WCy0rP0TjSa8kLzt1+SyXYmOoWbwSm/7dRZvqT/DZn8bhpp92raLhvTVYc3ALZfIVI9Ca1ZSEZDa73c6QAcMoWapEckICaNC4AVs2baV6zer8e+Q/EuLjyZU7F9NmfZFcZsqnUwkJCab1i88B0LXHmwBs2bSV2TO+YehIo4evYeMGbNm0hcJFnmTr5m0UL14sHbcw7ex2O8MHfkTxkiWSExJA3nx52b5lB1VrVGHLxq0ULVYEgB+Wzk8uM7T/cB6sX4cGjevToHH95OX/W7SYfXs0Xbp3AqBuwzps27yd6hHV2LJxKyVKlUiXbfPWk68/xpOvPwbAgR0HWTl/De3fb8OXg2exY81fVGtchU2/baFSnQoA5M6fi7+3HSDikRqc+vc08XEJhOUK49zJc+TKnwur1UrU6ShOH40kzz15CMsZSq58uTh99AwFiuZHbz/APcUzWU+mRfKMLzIyKc0GeiilTgDTXQ5sAqCUCgFex+ibn5DO9XMrJDAbTcrWost3w5KXPVWpEeOeeY98YblZ1GESO49rnviiCwD1SlXj2IVTHI46niJOtwUjmP7CELJlDeLX/WtZuu9PAGZsWsjU5wez/d0FxNniee3bD9Jv47ywc/tOFv+8hHvL3MuLLdoC0OXtzjz1bHOG9B9Gq6dfIGvWrAwaMRDLLX5JX37tJfr3GcCcr+cSEhJM/8Hvm7kJpvlr+y6W/vIrpcuU4qXnjB8fnd7qSN+BvRk3cgI2m43AwEDeG3jrI/u7dO/MkPeHMX7URHLlzkX/oZnzvfDkyQ6PM2PYbP731VKK3FuYWo9GAPB0p+bMHbuAVd//jsVioU3v1lgsFg7tPsLyb1dizWLFYrHQ6q1nCctpHDpq2e1pZo2Ygy3eRnjBPLTp3TojN+1GcvanTzKy+y4QYxROa4zRM/sxRjDFYhxLKIgx2igQ49hNO8dIG6+Z3X13uzK7++52Znb33e3MzO67O4HP3XePFkt7992S/6RZ5SLDWkqOBPOCUmoc0BLj/J8iXD9P6STGORwLnE84FEKITE3SjE8y/ORZR8KRpCOEuDNYJSv5IsOTkhBC3FFkoINPJCkJIYSZJCf5RJKSEEKYKUCyki8kKQkhhJkkJ/lEkpIQQphJjin5RJKSEEKYSUbf+USSkhBCmElykk8kKQkhhJmk+84nkpSEEMJMMvrOJ5KUhBDCTJKTfCJJSQghzCQtJZ9IUhJCCDNJUvKJJCUhhDCT5CSfSFISQggzyeg7n0hSEkIIM8mVZ30iSUkIIcwkLSWfSFISQggzyUAHn0hSEkIIM0n3nU8kKQkhhJmk+84nkpSEEMJMkpN8IklJCCHMJMeUfCJJSQghzCTddz6RpCSEECaySEvJJ5KUhBDCRBZpKflEkpIQQphIcpJvJCkJIYSJAiQr+USSkhBCmMhf3XdKqRlA+1SKFNFaH3eUrQOMAqoCl4B5QF+t9RWXmEHAEKAdkBvYCfTTWq9w8/qmx3RHzj0WQggTBQQEpPnmpSkYO3rn20vAFWCvU0KqDKwAsgHvANOANzCSiKsZQA9gNvA2kAgsUUrVdi7kj5ieSEtJCCFM5K/eO631emC98zKlVF0gBPjGafEI4BzQUGsd7Sh3BJiqlGqstV7pWFYTeB7oobUe71g2C9gNjATq+zmmW9JSEkIIE1ksljTfTPAiYAfmACilcgDNgFlJycNhFhANtHJa1hKIx2j1AKC1vgZMB+oqpQr6K2Zq7oqW0uFhCzO6CpmCGvlURlch09jY46uMrkKmkT84f0ZX4Y7iTbJRSuUCcrlZdUFrfeEmz82KkRDWaa2POBZXwtivb3Euq7WOU0rtAKo4La4C7HdJNACbMCZLqgyc9FNMj6SlJIQQJrJ48Q/oDhx2c+uehpd6GAgnZdddUkvE3Y7/JFDIpayncjiV9UdMj+6KlpIQQqQXL7vlxmMMDHCVaivJ4UWMrrL5TsuCHfexbspfc1qfVNZTOedY/ojpkSQlIYQwkdWLaYYcXXRpSUApKKXCgKeAX7XW55xWXXXcB7l5Wjan9UllPZVzjuWPmB5JUhJCCBOl0zRDT3PjqDu43k3mbkBBQeCES1lP5XAq64+YHskxJSGEMFE6jb5rgzHy7SeX5buBBKC680KlVCDGIIMdTot3AOUcrS5nEY77nX6M6ZEkJSGEMJHFkvbbrVBK5QOaAj+6zqagtb4ILAfauSSGdkAY8J3TsgVAVuB1p9hBwCvAWq31CX/FTI103wkhhInSofuuNca+27XrLkk/YB2wWik1DSgC9ASWaK2XJxXSWm9USn0HjHKcP3QIYxqj4sDL6RDTLWkpCSGEidKh+64NcAaj9XIDrfU2jJZULDAO6ABMBZ5zU/wlYILjfiJGK+cxrfVaf8f0xGK329NS7rZ2/MqRO38j06DG2NTmcry7yMmz1529FpnRVchUqoRH+NTUuWdI/TTvb04N+F2mFHch3XdCCGEiuXKFbyQpCSGEieTKs76RpCSEECaSpOQbSUpCCGEiufKsbyQpCSGEiQK8mGZI3EiSkhBCmMgx+7e4RZKUhBDCRHJMyTeSlIQQwkSSlHwjSUkIIUwkOck3kpSEEMJE0lLyjSQlIYQwUUCATCnqC0lKQghhImko+UaSkhBCmEi673wjSUkIIUwkSck3kpSEEMJEkpR8I0lJCCFMJDnJN5KUhBDCRDL6zjeSlIQQwkTSfecbSUpCCGEiyUm+8ZiUlFL5byWg1vrMrVdHCCFub9JS8k1qLaVTgP0WYlpvsS5CCHH7k6Tkk9SS0ihuLSkJIcRdSy7y5xuPSUlr/V56VuR2EBcbx9uv9SQ+Lh6bzUaDpvV4ufNL/Dh3Ed/P+ZETR0/y48r55MydE4AdW3byQY9B3FPoHgDqNX6Ql95oy39HjjK0z4jkuCePn+Llzu1o2eZZDupDjBs+kbjYOKxWK2+/35XyFctlyPbeTI6gMMY88S7l8pXEDrzz80g61GxJ6fCixvpsYVy6Fk2zaa8DUD5/KUY+1ovsQSEk2u08Nv0NYm1xLGg3ngJh4VyLjwXg+Tm9OHflAgDNyzeiZ/2XsWNn7+lDvLlwaIZsa2riYuPo8fq7yZ+L+k3q0r5zO0b0G8nfew+QJUsWVIWy9Oj3FlmyZuG/w0cZPWgsB/cf5JU329PqpZapxgFYOPcnfpizkBPHTvL9irnJn7HMJi42jsFdRhAfH0+iLZGIRjV47vVnsdvtzJuygA2rNhEQEECzZ5rwaKuHkp93aO8/fPDGEN4a3IVajWsCcPbUWaZ8+CXnzpzDYrHQ5+Oe5C+Yj11b9vDNJ3Ox2+1kCw6ic/+O3FOkQEZt8g2k+843t81AB6XUm0BPrXWpjKpD1sCsjP1iFMEhwSTEJ/DWq+9Q88EaVKxcgdr1I+jxeu8bnlOpSkVGTEy5Iy1WoihT500GwGaz0erhNtRt9CAAU8ZP46WObYmoW4MNf2zii/HTGTdttP837hYMebgbqw9touP3A8kakIXgrNno9OPg5PUDmnbhcmwMAFaLlUlP9eetRcPZe+YQuYNzEJ+YkFz2zYXD+OukThG/ZO7CdHuwDU/NfJOL16IJD8mVPhvmpayBWRkz5aPkz0X313pR48HqNHm0EX2HGZ+JEe+PZPHCpTz53BNkz5mdN3t3Yt2q9WmKc9/95alQ+T5q1Y+gZ4cbP2OZSdbArHww6T2yhWQjISGBgZ2GUbnW/Rw/coJzZ6IY++1IAgICuBh1Kfk5ibZE5nw2j/trVkwR69OhX/BM+ye5v2ZFrl25hsXRApk+egbvjuxO4RKF+e375fwwYxFd+ndM1+1MjSQl33iVlJRSFuA54CGgANBPa/2XUiqXY9nvWutT5lcTgFxAcT/FThOLxUJwSDAACQkJJCTYsFgslCl37y3H3LZpB4WKFOSeQgWSX+NKjLEjj4mOITxfHt8r7gfZg0KpVewBuv/0IQDxiQnEx0anKPPkfY147uvuADQoVZ19Zw6x98whAM5fvcTNtKnSnBlbfuTiNSNuUusps7nxc5GAxWIhom7N5DKqguLs6bMA5M6Ti9x5crHxj81pigP49BlLTxaLhWwh2QCwJdiwJdjAYmHZjyvpNrhz8jk8OfPkSH7O0gW/UbNRDQ7t+yd52bHDx0m02ZITVVLMpNe4EnMNgCsxV8mdN7fft8sbkpR8k+akpJTKBiwGGgJxQFZgnGN1NDAJ+BwY6EXM+mktC5T0oqzf2Gw2Or3YleNHT/B06+aUr5R619rev/bxeqtO5M0XzhvvdKBk6RIp1q/6dTWNH2mY/PebvTrR5833+XzcVBIT7UyaMY7MqFiugpyLucC45u9RocC9/HVS88Fvk7gab+wsIordT2R0FIfPHwegVHhR7MCcF0YTHpKLRXtX8tn6b5PjjWv+HomJNv63/3fG/znL8ZwiACxq/wkBlgA+/n0Gq//ZlL4bmkY2m40ubd7i+NETPNXqiRSfi4T4BJYvXsGbvTr5FOd2kWhLpO+rAzh17DQPPduUMhVKc/r4adYv38jm37eQPVcOXu7RloJF7yEqMorNa7bywSd9UySlk/+dIiQshI/7TiDyRCQVa1Tgxc6tCbAG0PG91xjZcwyBQYEEhwYzdGqadznpwt85SSlVAxgE1MHYDx8CxmmtZziVedJR5j7gDDAdGK61TnCJlQtj/MAzQAiwEXhHa73DzeuaHtMdb049Hgg8CLyA0WJJfusdlfoBeMSLeACrgVVpvL3qZWy/sFqtTJ03mfm/fsP+3ZrDB494LFum3L18u/hrps3/nKeff4oBPQanWB8fH8+6NRto0Ox6bv7pu1/o0vMN5i39hjd7vcGYwWP9tSk+sQZYqVSwDLO2LuKhaa9zJf4aXeu8mLz+6QpNWbhnRfLfWQKs1Cxaia4Lh/H0zK48oupRt0RVALouHEaTL17h6VndiCh2Py0rPZz8GiXzFKHF12/TZeEQxjzxLjmCwtJ3Q9PIarUyZe6nzF36Nfv3/J3iczHho0+5v0pFKlWt6DlAGuLcLgKsAYycOYzPFo7n0L5/OHroGPHxCWQNzMqIL4fQ5MkGfD5iGgAzx3/Di11a3zALgs1mY//Ov2nb9QWGTx/MmRORrF78BwCL5y2lz8e9+GzRBBo+Xo+vJ85J921MjcViSfPNW0qpR4G1GMnoA6AnsBwo6lJmIRAFdHM8HsD1RkRSuQDgf8DzGI2K3hg9YKuVUqXdvK6pMT3xpvuuFTBNaz1PKRXuZv3fQAsv4oHRwtoJjElD2ecwEmKmEJY9jMrVH2DTus2UvLeE2zKhYaHJj2vVq8mEDz/h4vmLyQepN/25mTLl7iVP+PXuh99+WUbX3p0BaNCsPmOGjPffRvjg5KVITl6KZPuJfQD8sm9NclKyWqw8purxyPSOKcpv+G8nUVcvArDy4AYq3VOWP49s49Rlo1srJu4qP+5eTpVC5Viw69fk+AmJNo5eOMWhc0cpmacIO0/uT+etTTvjc3E/m9dtoeS9JZg15Rsunr9IjzH9fYpzOwrNHkqFquXZsfEvwvPloWbD6gDUaFCdycONpPTP/sNMGPAZAJcvXmbHup1YrVbC8+ehRJliFChsnC5ZvV41Du45yKW6Vfj3wFHKVDD2b7WbRPDhO2nZfaQff00zpJTKCcwAJmut306l6BhgO/Cw1trmeO4loK9SaqLW+oCjXEuM1tYzWuuFjnLzMfblA4GX/BzTLW/evSKOSnkSA+RIZb07W4D8WutFN7sB+7yMbboLUReIvmwc34i9FsvWjdsoVqKox/JRZ6Ow241R9ft278duTyRHrutv0cqlKbvuAMLzhbNz618AbN+0g8LFCpm8FeaIjInixKVISucxtr9eyaocOHvE8bgaB8/9x8nLkcnlV/+zifL5ShGcJQirxUrt4g/w99kjWC1W8gQbSTpLgJWmZWqzP/IwAEv1n9QuXhmAPME5KR1elP8unEjHrUybC+ddPhcbtlOsRFEW/7iULeu30m9EnzTtqDzFuZ1cOn+JmMvGMdG42Dj+2rybQsULUr1+VfZs2wvA3u37KVjUGJE66fuxfPKDcYtoVINXe7WnRoNqlC5fipjoK1w6bxx73LN1L4VLFiY0eyhXY65w4r+TAPy1eQ+FS2Su74gfW0ovYhxbHwCglMruOM6fTCl1H0b32pSk5OHwGcb+3rnh0BI4ASxKWqC1jgTmA08rpbL6K2ZqvGkpnQfuSWV9eeCkF/EANgHvKqVya63P36SsBacuw4xw7mwUIweMITExkcTERBo2q0/t+rX4Yc5C5s78jqhzUbzeqhMRdWvSa2AP1iz/g5+++wWr1UpQtiD6f9g3+YN49eo1tm7cRo/+KX/w9PygO5+MnowtwUZgUCA9+3fPiE1Nk/6/TuCTp/uT1ZqV/y6coMfPHwHwVIXGKbruAC5ei2bKxvksfm0KdrudlQc3suLgBoKzZmPOi6PJEpAFa0AAfxzeyjfbfwGMRNagVA1WvzETmz2Rocsnp2mARHqLijzPyIFjSLQlYrfbadCsHrXqR/BQjccpUDA/b738DgB1G9ehXcc2RJ2Nokvbt7gScwWLJYAf5ixk+oIpHuMA/PjtIubN/I6oc+fp2LoLNevWoOeAzPfZOH/uApOHfkFiop3ExERqN4mg2oNVKHd/WT4Z9DmL5/5KtuAg3uj7WqpxAqwBtO36AsPeGondbqdkuRI0ebIh1ixWOrz3KuPen4QlwEJo9lA6vf96Om1d2vjxmFJTYD/wmFJqFEZD4YJSagrGoDMbUMVRdovzE7XWJ5RSx5zW43i8VWvtej7qJqAjcC9GY8AfMT2yJP2Svxml1BygJlARCAUigaZa65VKqSLAHmCu1vqNNAU0Yt4DKGCL1jomrc/z1vErR+QkYKDG2PYZXYVMY2OPrzK6CpnG2WuRNy90F6kSHuFTWqn7zQtp3t9EDtmWG6P14+qC1jrFcFOl1E6MY0ehGAMJtgNPAK8AE7TW3ZVSvYDRQCGt9UmX528CYrXW9Rx/RwPfuO6zlVKPYRwXaqq1XuGPmKm9J960lIZgZLsNwDeOZY2VUvWArkAi8KEX8XAMH/fXEHIhhEh3XnbLdcf9iOXBGCPdnIUBuYH3tNYjHct+UEqFAV2UUsOAYMfyWDcxr2GMhksSnEq5pPXO92bG9CjNx5S01vsxzkUKApLekPcx3tBzQDOt9ZG0xhNCiDuRl8eUxmOc7uJ6czfC6arj/luX5d9gjMar6VQmyM3zszmtT4rnqZzz6/kjpkdenTyrtd7gOOhVDeMYkgU4AGzUWid6E0sIIe5E3sx95+iiS+tZ4SeBCsBpl+VJf+fm+nH9gtx4jL8gsM4lXkE3r5O07IRTObNjeuT1NEOOA1hbcDnoJYQQAn+OdNiKMdihMPCP0/IijvtI4LjjcXVgW1IBpVQhRznnE1h3AHWUUhaXgQkRGKfrHHQqZ3ZMj7weUK+UyquUaq+UGuy4tVdK5fM2jhBC3In8OCT8O8d98tBFx5Dw1zFOydmgtd6DMUKvo1LK+TJCnTGO+3/vtGwBUAh4yileXoxzQhdpreMB/BEzNd7OffcuxoCHQFIOz45VSg1yOvgmhBB3JX9duUJrvVUpNQvjhNX8GK2Wx4GHgd5a66TzJd4FfgJ+VUrNwxgx3RXjPKO/nUIuwBi4NkspNQY4C3TBaKwMcnl5f8R0K80tJaXUGxgDHPZjZOpajttrgAZGOMoIIcRdy5/TDAEdgOEYiWgCxnk/nbTWyZcS0Fr/AjwLhGNM9fMsMAx4yzmQ47ymxzBObH0LY9h3JNBIa33QpazpMT3x5jylfRh9gg9qreNc1gVhHOwK1Vpnuhkk5Twlg5yndJ2cp3SdnKeUkq/nKT384ytp3t/8+sxXMqW4C2+OKZXEOCkqznWF1joWmE0GX1pCCCEyWoAXN3Ejb44pHcU4k9iTEOCYb9URQojbW4BcT8kn3iTryUAHdyPtlFIFMOY1+sysigkhxO3Iz8eU7ngeW0pKqVYui45jjKTQSqmvMAY8gHESbXuMcfOZbwpnIYRIR9JS8k1q3XdzATvXh347P+7hpnw1YA4wz7TaCSHEbUZaQL5JLSk9mm61EEKIO0QWSUo+8ZiUtNa/pmdFhBDiTiAtJd94PfedEEIIz+SYkm+8TkpKqYoYk+vl5sbRe3bnM4uFEOJuIynJN2lOSo5ZG+YCT2K87+4GQdgxppUQQoi7krSUfOPNeUr9MWZ+/Rh4BCMJdcCYA2kTsBmobHYFhRDidmINCEjzTdzIm3elFfC91ro3xnU9AA5rrRcCDTAuc+t6bpMQQtxVAiyWNN/EjbxJSsWBVY7HSVeZDQRwzIc3B2hjXtWEEOL2Y/HiJm7kzUCHaK4nscsYiekep/VRuL8MrhBC3DWkBeQbb1pK/wBlALTWCcA+jONJSZ7i+qV4hRDiriTdd77xJiktB1oopZKeMw14Qim1Vym1F2Pww0yzKyiEELcTmZDVN94kpZEYl961AmitJ2CMyAOwYVwmfbiptRNCiNuM1WJJ803cKM3HlLTWF4GdLstGACPMrpQQQtyupFvONzLNkBBCmEiSkm9Su55SzVsJqLXedOvVEUKI25scK/JNapDTQgwAACAASURBVC2lDRjTBqVV0jRDVp9qJIQQtzGZp8E3qSWlzulWCyGEuENIS8k3qV1PaUp6VkQIIe4EWWROO5/cFQMdLsZdyOgqZAoruk7M6CpkGo/P7J7RVcg0vm/zYUZX4Y4iLSXf3BVJSQgh0kuAzGrnE0lKQghhImkp+UaSkhBCmMhf5ykppRpy/UoNrsprrfc7la0DjAKqApeAeUBfrfUVl5hBGLPxtMO4mvhOoJ/WeoWb1zc9pjtyRE4IIUwUYAlI8+0WjcfY4TvfTiStVEpVBlYA2YB3MOYpfQMjibiaAfQAZgNvY1z9YYlSqrZzIX/E9ERaSkIIYaJ0mNFhjePiqp6MAM4BDbXW0QBKqSPAVKVUY631SseymsDzQA+t9XjHslnAboy5Tuv7OaZbt5SqlVIBSqlwpZQkNSGEcGIhIM23W6WUyu5u/6uUygE0A2YlJQ+HWRjXxHO+OnhLIB6j1QOA1voaMB2oq5Qq6K+YqfEqqSilKmFku0ZAVuAhYKVSKj/wFTBaa73am5hCCHEn8aalpJTKBeRys+qC1trTuSxfA2FAglJqFdBTa73Lsa4Sxn59i/MTtNZxSqkdQBWnxVWA/S6JBmATxgw9lYGTforpUZpTtVKqIrDOEXQBTlfz1VqfAfICL6c1nhBC3Im8vJ5Sd+Cwm5u7E+niMPa9b2NcVHUwUBP4UylV1lEmqSXibsd/Eijk9HfBVMrhVNYfMT3ypqU0FIjEGHmRBWjjsn4ZRtNNCCHuWhbvzlMajzEwwNUNrSSt9TqMhkGSn5RSP2O0YAZi7JODHeti3cS85rQex2NP5XAq64+YHnmTlOpjdM9dUEqFu1n/H2nIgkIIcSezejHNkKOL7pannNFa71RKLQeaOBZdddwHuSmezWl9UllP5Zxj+SOmR94caQsBolJZHwZyKrMQ4u4W4MU/kxwF8jgeJ3WTuRtQUBCnoeOOsp7K4VTWHzE98uZd+YeUB7RcNQT2p7JeCCHueF4eUzJDKYxDK2AMvU4AqjsXUEoFYowH2OG0eAdQTikV5hIvwnGfdKVxf8T0yJukNA9or5RyHmdud1TuTeBx4Bsv4gkhxB3HX0lJKZXPzbK6GKOhfwXQWl8ElgPtXBJDO4zerO+cli3AGEX9ulO8IOAVYK3W+oS/YqbGm2NKo4CHMc7q3YWRkEYqpfICxYE1wCQv4gkhxB3HjxOyzlNKXcEY7HAWqAh0dDwe5FSun6PMaqXUNKAI0BNYorVenlRIa71RKfUdMMpx/tAhoD3G/vxll9f2R0y30txScpwA1QgYAARiTB1RFeNEqQHAI1prW1rjCSHEnciP3XcLgXwYyeBToAUwB6ihtf4vqZDWehvQFGMU3DigAzAVeM5NzJeACY77iRitnMe01mudC/kjpicWu92bK56npJSyaK1vPUA62XthR6avY3rwcqjqHa31nA8yugqZhlxPKaUyOSv49EUZt3NMmvc3PR7oJV9KFz5NE3Q7JCQhhEhPPky0KvAiKSmlWt28FGit5996dYQQ4vYm11PyjTctpbkYgxtc33HX1pIkJSHEXUu6yX3jTVJ61MPzSwOdMM5KHmJGpYQQ4naVDpeuuKOlOSlprX/1tE4pNRVj/qWywFIT6iWEELclqxxT8okp757W+irGtTW6mRFPCCFuVxZLQJpv4kZmXqTvClDUxHhCCHHbkWNKvjElKTlmdegI/GtGPCGEuF3JMSXfeDMkfLGHVXkwrkwYjNN8R0IIcTeSIeG+8aalVJUbh3/bMS5n8SvwidZ6pVkVE0KI25Ef5767K3gz+u4ef1ZECCHuBAEB1oyuwm0tTUlJKRUCdAW2aq1X+LdKQghx+5KWkm/SNCZRa30FGIpxMSkhhBAeZMBF/u4o3hxT+gfI76+KCCHEnUCGhPvGm7O3PgdeVUrl9FdlhBDidictJd9401I6BVwCtFJqOnAA44TZFO7kWcLjYuPo12kQCXHx2GyJ1G4cwQsdWzFxyGfs2baXkLAQAN4a0IWSZUtgt9uZPnYGW9dtJyhbEN0+6EzpckYP6Mr/rWHBlz8A0PLVZ2n8eAMAhrw9gvNnz2OzJVK+cjk6vvsaVmvmO/PbeC8GEh+XgM1mo07jWrzQ8fpE8lM//pIVP69i7uqvAZg+bga7tu4xnnstjgvnLzJnxQwAZn4ym61rtwPQ6tUW1G1WB4C+HQdw9cpVAC6ev0SZ+0rz/uje6bWJXskeGMqgRl25N09x7NgZsHIi9YpXp1HJCBLtiURdvcgHKyYQeSUq+TkV8t/L18+Ops9vo1n2zzoAnlSN6VDNeB+nbp3PT3ol2bIEMubhPhTNURCbPZE1RzYxYcOsDNnOm4mLjaPPG/2Jj4sn0ZbIg01q06bj88nrp4yZxrKfV7JgzRwA4uPiGTtoAgf3/0P2nNnpM7wnBQrlZ9XSNfzw9aLk5x05+C8Tvh5DqbIlObjvEOOGTCIuNo7qdarSsedrmWoHL8eUfONNUvrW6XFfD2Xs3MGzhGcNzMqQTwcQHJKNhIQE3u84kKq1KwPQvltb6jSplaL8tnU7OHH0FJ8tmMDfuw8wZdR0Rn05nMsXo5k/bQGjZ3yIxQK92velZr1qhOUIo9fw7oSEhWC32xn13ljWrVhPvYcezIjNTZXxXgxMfi/6dhxA1dqVUZXKcnDfIaIvxaQo/1qPl5Mf/zJ/CYf1YQC2/LmNf/Rhxn09ivj4ePp3HkzV2pUJCQvhwy+uz+/7UZ8xRDSokS7bdiv61O3A2v+20fPXkWQJyEJwliAORf3Hp5u+AeDFSk/wRo3WDFszGTCuudOj1susP7o9OUaOoDA6VX+e5xe8gx0781qOY9WRjcTb4pm5fSGbT+wiS0AWpj05lLrFqvLnf9syZFtTkzUwKyM+G0xwSDAJCQn07tCParWrUK6S4sDeg0RfTvm5+O2n5YRmD2PqD5+x5rc/mfHJLPqM6EWjRxrQ6BHjh9qRg/8y7N2PKFW2JACfjpxCt/c7oyqWZVD3YWxdv53qdaqm+7Z6EmCR0Xe+8OYn+KNpuD3mzYsrw5dKqfVKqZ+VUm09lHtKKfWPN7H9wWKxEBySDQBbgg1bQkKqv9A2/b6ZRo/Wx2KxoCqVJeZyDFFnz7Njw04eqFmJ7DnDCMsRxgM1K7F9/U6A5NaWzWYj4SbxM9KN74UNi8WCzZbIjImzad/N7X8lAH/8tpZ6D9UF4OjhY9xXuTzWLFayBWej+L3F2LZhR4ryV6KvsGvrHiLqZ86kFBYYQrVCFfhh3zIAEhITuBwXQ0z81eQywVmzpTjL78VKT7Dsn3VEXb2YvOzBolVZf2wHl2KjuRwbw/pjO6hbtBrXEuLYfGJXcux9Zw9RIDRv+mycl4zPRTAACU7fEZvNxpeTZvFKt3Ypym9Ys5kmjzcCoG7j2uzcvAvXq2Gv+e0P6jczPi9RZ6O4GnOVcpUUFouFxo81ZMOajemwZWkn3Xe+SbWlpJQqBkRqra+mNkv4rVBKlQY2Y1y/fQ9QGXhcKfU60EprfcapeBhQ3MzXv1U2WyK92r/HqWOneLTlw5StWIalPyzjm8/nMv/L77m/ekXavfkiWQOzci7yPOEFwpOfG54/nKjIKM5FRpHXZfm5yOvdOoPfGs6BvYeoWrsytRunbH1lJjZbIj3b90nxXvw8dzE161cjT97cbp9z5mQkZ06coVL1igCUKFOcedMX8HSb5sRei2X31j0ULVkkxXM2/r6Z+6tXTE7YmU3h7AWIunqRoY3fpmx4SfZFHmTkn1O5mhBLt4i2NFeNiI69wmuL+gGQPzQPjUvW4rVF/ajYuExynPxheTgVfTb579PR58gflifFa2UPDKVB8ZrM/uvn9Nm4W2Cz2ej+0rucPHaKx1s+gqpYlkVzfyGiXg3y5E25Peciz5HP8V2wZrESEhbCpYuXyZkrR3KZP5atpf+Y94zyZ6IIz+/y3TkTRWYiAx18c7OW0mHgGT+99jAgBqikta6utS4KvISRnNYrpe710+v6xGoNYNzsUUz7eTIH9hzk30P/0bbLC3wyfxyjvxrB5UvR/DBr0c0DpWLgxH58+b/PiY+LZ9eW3SbV3HxWawDjZ49m2s+fc2DPIfZs38u6Fet5/Dl3l94y/LlsLbUb10o+Tlal1gNUq1OFPq/35+MPJqAqlSUgIOXH0mhZZb4uzCTWACvl85Vm/u4ltP6uO1cTrvFq1ZYATNo4m4dmvcb/DqzhhUqPA9D7wQ6M3zAT+w0TpNzkdSwBjGzWizm7fuH4pdOmb4dZrFYrk74Zy4xfpvL33oPs3raHtSvW0byVVx0pAOjdfxOULYgSpTPFb9I0kZaSb26WlPz5rtUBJmmtDyYt0FrPBpKaBuuUUpmzvwYIzR5KxWoV2L5+J3ny5sZisZA1MCtNnmjIgb2HAAjPl5tzp88lP+fcmXPkyZeH8Hx5OOuyPDxfyl+QgUGB1GxQnU2/b0mfDfJBWPZQKlWrwK6tezh57BSdWr5Fh6ffJPZaHJ1apLyayR/L1lHfJcE898qzjJ89msGTPsBut1OoWMHkdZcuXOLAnoNUfzDzHDNwdTr6LKejz7LrzN8ALDu0jvL5Up7S97+/V9O0lDGAo0L+exnZrBdL2k6lWek69KvfiUYlIzgTHcU9Yde75QqEhXMm+norYEDDrvx78QSz//opHbbKd2HZQ7m/WkX+2rqbE0dP0aFFF1596g1ir8XS4dkuAITnCyfS8V2wJdi4En2FHDmzJ8f4/bc/aeDo6gUIz5+Hc2dcvjv5U353MloAljTfxI0yclhXOMaIvhS01vsxEtZxYKVS6uH0rpgnF89fIsZxoDb2Whw7N+2icIlCRJ09D4Ddbmfjms0UK21cwaNGveqsWvI7drsdvetvQsJCyJM3N5VrPcCOjX8RfSma6EvR7Nj4F5VrPcDVK9eSY9kSbGxdu50iJQplzMbexMXzl5IPWsdei2PHpr8oXa4UM5ZMZerCT5m68FOCsgXy+feTkp9z7Mhxoi/HoCqVTV5msyVy6eJlAI4c+Jd/D/5HlYgHktevW7mB6nWrEhgUmE5b5r1zVy9wOvosJXIVBiCiyAP8E3WUYjmvJ9dGJSM4fOEYAI/O7pB8W3ZoHcN//5xVhzey9ug26hStQvagULIHhVKnaBXWHjUGM3St2YbsgSGM+nNa+m+gFy6ev+j0uYhl+8ad3FuuNLOXfsmXi6bw5aIpBGULYuoPnwEQUb8GK/63CoA/V67n/uqVklsQiYmJ/LFiHfWdklKevHkIDg1m/y6N3W5n5eLVRNSvmc5bmboAizXNN3EjM6+n5K1/gfvdrdBan1ZKNQB+AX4ClqRnxTw5f/Y8E4d8RmJiIomJxnDXGnWr8UGXIVy6cAm73U7JsiXo1KcDANUerMLWddvp3OJtgrIF0u2DzgBkzxnGc6+24N1X3geg1WstyJ4zjAvnLvBhr1HExyeQmJhIpWoVePiZZhm2vak5f/Y8E4Z8SmJiIvZEe/J7kZo/lq2lXrM6KbotbAkJvN9xAAAhoSF0H9wNaxar03PW0eKlp/2zESb68I8v+LDpO2S1ZuXYxVN8sGoCgxt2o0SuwiRi5+TlMwxd81mqMS7FRjNlyzy+bTkWgM+3zOVSbDQFQsPpWL01/5w/yrxW4wCYu+t/yQMrMpOos+cZN3hS8nekXtMHqVmvusfyDz3ZhI8HTqDDs10IyxFGn+HvJK/bvX0v+QqEc0/hlNNudundMXlIeLU6VTPVyDuQWcJ9ZXEd6eJMKZUITAHWpzWg1jpNJ1AopT4FngaKa60TPJQJwhhi3hywa61v6afF3gs7vOu8v0PJAdjrWs/5IKOrkGl83+bDjK5CplImZwWfvig///t9mvc3zYu3kC+li7S0lDo6bjdjwRj0mtaz+r7CmLaoOrDBXQGtdaxS6hlgLPCAuzJCCJGZyEX+fJOWpPQFHpKGL7TWW4Dn0lAuEehu9usLIYQ/pFePhFKqNzAS2Km1ruyyrg4wCuM6eJeAeUBfx+TazuWCgCFAOyA3sBPo5+5qEP6I6U5aktIfWus5aQkmhBB3u/Q4pqSUugfoj3Fajeu6ysAKjPM/3wGKAL0wrvLQ3KX4DKAFMB44CLwMLFFKNdBaJx+28UdMTzJyoIMQQtxx0mlU3UfAFowR1Llc1o0AzgENtdbRAEqpI8BUpVTjpCuEK6VqAs8DPbTW4x3LZgG7MVpg9f0c063MN9OnEELcxvx9npJjx98Wo8Xiui4H0AyYlZQ8HGYB0UArp2UtgXgg+TwDrfU1YDpQVylV0F8xUyNJSQghTOTPGR2UUhZgEjBTa73DTZFKGD1gKc6611rHATuAKk6LqwD7XRINwCaMgWtJx6n8EdOjVLvvtNaStIQQwgveDHRQSuXixu43gAta6wtulr8E3IdxOo07SS2Rk27WnQRqu5Q97qEcQCGncmbH9EiSjhBCmMjLllJ3jDlGXW83jDhWSmXHOJb0kdbaXYIACHbcx7pZd81pfVJZT+WcY/kjpkcy0EEIIUxk9W6gw3iM0Wqu3LWS+gNxGOdtepJ0vZQgN+uyOa1PKuupnHMsf8T0SJKSEEKYyJvuO0cXnbsElIJjgEB34AOggFIqaVU2IFApVQK4yPVuMncDCgoCJ5z+PplKOZzK+iOmR9J9J4QQJvLTQIcCQCDGsGrnbr4IoLzjcR+ModcJGDPlJFNKBWIMMnAeHLEDKKeUCnN5rQjH/U7HvT9ieiRJSQghTGTx4p8Xkq5t53rbAxxxPJ6ltb4ILAfauSSGdhgXS/3OadkCjIusvp60wDEbwyvAWq31CQB/xEyNdN8JIYSJ/DGjgyMxLHRdrpTqDiRorZ3X9QPWAauVUtMwZl/oCSzRWi93irlRKfUdMMrRPXgIaI9xle+XXV7KHzHdkpaSEEKYKMCLf/6gtd4GNMUYBTcO6ABMxf1coy8BExz3EzFaOY9prdf6O6YnqV664k4hl64wyKUrrpNLV1wnl65IyddLV2w883ua9zcR+evLl9KFdN8JIYSJ5CJ/vpGkJIQQJpIeCd9IUhJCCBNJUvKNJCUhhDCTdN/5RJKSEEKYSFpKvpGkJIQQJgqwyJk2vpCkJIQQJpKWkm8kKQkhhIlkSLhvJCkJIYSJpKXkG0lKQghhIklKvpGkJIQQJpKBDr6RpCSEECaSY0q+kaQkhBAmku4730hSEkIIE0lS8o0kJSGEMJF03/lGkpIQQphIWkq+kaQkhBAmktF3vpGkdBfJH3xPRlch09j0xtyMrkKmEfxI2YyuQqZiX3bMxwjSUvKFJCUhhDCRHFPyjSQlIYQwkRxT8o0kJSGEMJEkJd9IUhJCCBNJ951vJCkJIYSJApDRd76QpCSEECaSlpJvJCkJIYSJ5JiSbyQpCSGEifzVUlJKVQf6AVWB/MBFYAcwRGu9zqVsHWCUo+wlYB7QV2t9xaVcEDAEaAfkBnYC/bTWK9y8vukx3ZHOTyGEMJHFi39eKo3RkJgKdAVGYySn35VSzZIKKaUqAyuAbMA7wDTgDYwk4moG0AOYDbwNJAJLlFK1nQv5I6Yn0lISQggT+av7Tms9D5ckoJSaDPyDsfNf5lg8AjgHNNRaRzvKHQGmKqUaa61XOpbVBJ4HemitxzuWzQJ2AyOB+k4v5Y+YbklLSQghTGSxWNJ885Wj6ywSyAWglMoBNANmJSUPh1lANNDKaVlLIB6j1ZMU7xowHairlCror5ipkZaSEEKYyr8DHZRS2YEgIBxoD1TEOIYDUAljv77F+Tla6zil1A6gitPiKsB+l0QDsAljIyoDJ/0U0yNJSkIIYSJvUpJSKheOVo6LC1rrCx6e9hXQwvE4Dvgco3sNIKkl4m7HfxJwPq5TEDjuoRxAIT/G9Ei674QQwlQWL250Bw67uXVP5QUGAw8BrwJrMVpNWR3rgh33sW6ed81pfVJZT+WcY/kjpkfSUhJCCBN5eaxoPMZoNVeeWklorXcBuwCUUrMxutVmYBzPueooFuTmqdmc1uN47KkcTmX9EdMjSUpCCGEib0bfObroPCagNDw/Xim1COivlArmejeZuwEFBYETTn+fTKUcTmX9EdMj6b4TQggT+fE8JU+CMfoCs2MMvU4AqjsXUEoFYgwy2OG0eAdQTikV5hIvwnG/03Hvj5geSVISQojbgFIqn5tlOYDngKNa6zNa64vAcqCdS2JoB4QB3zktW4BxLOp1p3hBwCvAWq31CQB/xEyNdN8JIYSJ/Dgh6zyl1DVgHXAKKIqxsy+CccJqkn6OMquVUtMc63sCS7TWy5MKaa03KqW+A0Y5zh86hDHEvDjwsstr+yOmW9JSEkKI28NsIAR4C5gMdMHoDmuktZ6fVEhrvQ1oijEKbhzQAWNqoufcxHwJmOC4n4jRynlMa73WuZA/YnpisdvtaSl3W9t7Ycedv5FpUCD4pidT3zVCs2TP6CpkGsGPlM3oKmQq9mXHfGrqRMWeSfP+Jk9QfplS3IV03wkhhInk0hW+kaQkhBAmkov8+UaSkhBCmEqSki8kKQkhhIkkJflGkpIQQphK0pIvJCkJIYSJ5JiSbyQpCSGEiWT0nW8kKQkhhKkkKflCkpIQQphIUpJvJCkJIYSJ5JiSbzJtUnLMLJtda302o+uSJC42jn6dBpEQF4/NlkjtxhG80LEVE4d8xp5tewkJCwHgrQFdKFm2BMeOHGfS0Mn8ow/TptPzPN22OQBnT59lwqBPuRB1EYvFQrOnm9D8+ccAuHwxmo/7j+fMiUjyF8pHr+HdCcvhOgt8xjt96jRD+40g6lwUFouFJ1s0p3Xb5/h7/wFGD/2YuLg4rFYrvfr14L5K9/HNV9/y2+JlACQk2Pj38L8sXvMTOXLmYMOfGxk/ciK2xESaP/s4L73WFoAtG7byydjPsNvtBIcE039oX4oUK5KRm+3WqZOn6Nf3A6LOngOLhZatWtCm3YvJ62d+NYuxo8exeu1KcufOzaoVq/h00mQCLBasWay8+967VK1WBYBxY8bz+5o/sNvt1KodQZ/3e2OxWIiPi+fD4R+xedMWAgIC6Pb2mzR9qGlGbbJHZYuUYl7/ycl/l7qnGANmjmHVznV8/vZHhAWHcuTUUdp81I3LV6IpXqAI+6avRh87BMCGfdvoPKEvAMNe6c1LTVuSO3tOsj+pkmMWzVeImb3HkyssB9YAK+9N/5Alm1am74amSpKSLzJ07julVBPgbYxr1C8HPgQCMa5B/yzG/+5/QC+t9fe3+jpmzX1nt9u5djWW4JBsJCQk8H7HgbzWoz2//ric6g9WpU6TWinKX4i6SOSpSDau2UJY9tDkpBR19jznz56ndLlSXI25Ss/2fek7qhdFSxVh5qTZhOUIo0X7p/l+5kJiLsfwUtc2ZlTf1Lnvzkae5VzkOdR9ipiYK7z6/Ot8NH4E40dN5Pm2rahdrxbr/ljPN199y6dfTkzx3D9Xr2Xu1/P5ZPoEbDYbrZu3YcIXY8lfIB+vvdCRwSMHUrJ0CVo3f5GRE0ZQolQJvp/7I/t276P/sPdNqb+Zc99FRkZyNvIs5e8rT0xMDM+3fJHxk8ZS+t7SnDp5ikEDhnDkn8N8u2AOuXPn5krMFYJDgrFYLPyt/+bdd/qw6H8/smP7DsaNGc+Xs6YD8HLbV3irx1vUqFmdzyZNJjExka5vv0liYiIXL14kd+7cptTfX3PfBQQEcPzbLUR0a86CAVPo9cUwfv9rA6883JqS9xRlwMwxFC9QhF+GzqBSxxsTbET5qvx7+hgHZvyRIilN6T6S7Qd38/kvX1O+WBkWD59FyXa1Tau3r3PfXUmITvP+JiRLmGQwFxk2S7hSqjawFKiBkZQGYlwaeAJQFhgOjMVITPOUUnUzqKrJLBYLwSHGVX1tCTZsCQmpNtVz5clJmfvuJUsWa4rlefLmpnS5UgAEhwZTpERhzkVGAbDp9y00erwBAI0eb8DGNZv9sSk+y5svL+o+Y0cRGhpC8ZLFiTwTicViISYmBoDoyzHkzZf3hucuW7KCZo8aO6G9u/dRpFhhChcpRNasWWn6SBP+WPUnYIxiiom+AkBMtPtYmUG+fPkof195AEJDQylVqiRnzkQCMHrkGHr0fDvF5yQkNCT576tXryY/tlgsxMbGER8fT1xcHAkJCYSH5wFg4Y+LeLXDq4CxszcrIflTkyp1OXTyX/47c5yyRUrx+18bAFi27Xda1Hvsps/fuG8bp6LO3LDcbreTI9T4UZEzNDsnzp02t+I+slgsab6JG2Vk990AjGnX62mtryqlRgDvAH8C1bXWCQBKqaEY16Pv5ViXoWy2RHq1f49Tx07xaMuHKVuxDEt/WMY3n89l/pffc3/1irR780WyBmZNU7wzJ85w+O/DlK1wL2C0rvLkNXY4ucNzcSHqot+2xSwnj5/kwP4DVKh0H917d6NHp1588vFnJNrtTJn1WYqy165eY8PajfR8vzsAkafPUqBA/uT1+QrkY++uvQC8N6g3Pd/sTVBQEKFhIUyd/Xn6bdQtOn78BPv3aSrdX5FVK1aRP39+VDl1Q7kVy1cycdwkos5F8cnnRkvygcoPUKNmdZo2aIbdDs+/2JpSpUtx6dJlAD6d9ClbNm2laNEi9O3/HuF5w9N127z1fMMn+XbVIgD2HPmbp+o8zKJ1v/Jc/Scomq9QcrmS9xRj2+SlXLoSTf+vRvHn7k2pxh309Vh++2gO3Z56hdBswTTt84Jft0OkrwzrvlNKnQRGaa3HOf4uC+wHXtFaz3QpOxjopLUukP41dU8plQv4EegGnMO46FYg8AVwSGs9xKnsICBaaz3GJUYYsAYYrrX+wbHsgtY6l1OZ81rrTPuz2HUblFITgTVa6++VUq2Ajlrrpk7lWwNttdbNHX+3BB7RWr/u+LsdEKG17qqU+gEY6bhw2LuASiqXGTm/Fxi9AKuAh7TWF5VSR/7f3p1HX1HWG5f+CwAADMpJREFUcRx/kwuLKbmmhakg50vuK6YWi4FWJzug5hqIYmplrqUdxBSsLMtCMyncKOCguKRQmlup57iVIYqKHzEVd1IEDRS1+PXH95kcLvf347fdOxP3+zqHc3937jNzn2f0zneeeWaeL36y9UbFOgOA70saYmbb4lcKDksf3wGcCcwDXge+Kul6Mzsd2FXSiDo0q73WBV4BtgcWAv3w3DobAzPxnEAbA13x7KWLgN2Bm9I6b+e2tTSVyZyOX0G5CNgbuBLYAVhRs9aEuikyyV9PYEnu/aL0+lKVsi/gl/hKQ9IS/KDzBUmvSmqS9B4+HtZ/deub2TrADcC0LCAlC1PGRtLrqtcvSqKZNhwNZH9fx6r74nBgeu79y3gGzUwv4OWU+nlnSQ+l5dcC+3Ri9TtVlX3RB9gGeDQFpF7AbDPbPL+epHuB3ma2CTAceFDSUklLgVvxg+4i4B1W3q+71bxRHfNFYDYekMBPOPfHA890PCMpeNK47Lf/97R8dYNco4Esqd0DQDegnNd2Q5sVGZT+CeRH3t/Df9SvVSm7ObC4HpVqiZltmnpImFl3YCjwVC6IdAGGAY+vZjtd8LO7eZJ+XvHxTPzATnq9ufNa0HlaaMMrwMD0937A/Nw6PdNn+Tb9DehrZtuY2bp40JqJ//fumXrQ4Pt6Xi3a0lHV9oWkuZI2k7S1pK3xk63dJL1mZtumdTCz3fDewiL85Gugma2dgtzAtM0mYBYwKH3l54En69fCdjmClU8+smu0HwHGAtm12E2BbNC1N9AXeHY1234B3wcAn8aD0usdrG8oiSLHlGYDe2Vv0plhtdS64GfIZfgRbgH81szWwn9cMyT9wcz+nM7suwBzgBMB0lnxw8AGwAozOxXYDtgJGAHMNbM5adtjJN0C/BiYYWajgQXAofVrXpvsS5U24GmSLzaztYHlwPG5dYYDt0tali2Q9G8zOwm4DT84XSXpCQAz+zpwg5mtwIPUsTVuU3tV3Rfpv2c1BwMjzewD4F3gMElNZnY9HsjnAk3AnyTNSuucBUwxswn4AfiYGrWlM6yHn0SckFt2BPCt9PeN+BUFgAHAeOAD/PLbicCb6bMLgSPxFOAvAVcA5wFn4Km4T8P306j0GtYARY4p7Q70yeeWb6bcJvilmymSJtejbiGEEIpR6HNKIYQQQl6RY0ohhBDCSiIohRBCKI0ISiGEEEojglIIIYTSiKAUQgihNEqbumJNkNJvjMefYdkQn+vvbEl3FVqxAqQHjE/Bn03bA582ZrCku4usV72Z2Z74czWDga3wh2bvB8ZKeqbAqtWdme0BnI3PTrEZ8Bb+nN94SfcXWbdQnOgp1dZk/AG/qfgBeQVwa5ohvdEY/gBoL+CxgutSpLPwtCx34v9PTMJnanjEzD5dYL2K0Ac/Mb4cOAn4KR6c7jWzoUVWLBQnnlOqETPrDzwEnCZpQlrWDZ+C6BVJA4qsX72Z2frAupIWmdkwfDLbRuwp7QM8LOn93LK++CwO10gaVVTdysDMeuDTDD0s6ctF1yfUX/SUaucQfOqUK7IFkpbjc6R9Npsvr1FI+pekRasvuWaTdH8+IKVl84En8HncGpqkd/BplEo1AXOonxhTqp1dgafSnH55f8XnyNsFeLXutQqlkyZn/Tg+5thwUi+6K57K4mg8DcX4FlcKa6wISrWzBZ6WoVIWiD5R5bPQmI4CPokP+jeiq/FJagHex2cQ/1Fx1QlFist3tdMdT8dRaXnu89DgzKwf8Cs8q/KUgqtTlHF4rqVjgfvwXlPrUjeHNU70lGrnXfzHValb7vPQwFJqkz/iaTm+KqkhM6dKmovf6IGZTcXTvUzGx2VDg4meUu28yspJDDPZslfqWJdQMinh4a14BuYDJFVLbtlwJH2AJ4E8KCXSDA0mglLtzAH6mdlHK5ZniQ0bclA7/O/RgFl42u8vS1LBVSqb7vjNQOsXXZFQfxGUaud6/Lr4cdmCNMPDMcB9kqKn1IBS1uJrgb3xS3YPFlylwqRszZXLNsAzUL8o6Z/1r1UoWowp1Yikh8zsOuDC9EzSP/DbXbfCp5lpOGY2Nv2ZPY8zwsw+CyyRdGlB1aq3i4Cv4D2ljczsa7nPlkq6qZhqFeJaM1uOT7P0GrAlftLWCzi8yIqF4kRQqq2RwPnpdUN8ep0vSbqv0FoV5/yK98em1wVAowSlXdLrgelf3gKgkYLSVPy3cTL++1gCPAiMkHRPkRULxYlphkIIIZRGjCmFEEIojQhKIYQQSiOCUgghhNKIoBRCCKE0IiiFEEIojQhKIYQQSiOCUgghhNKIoBQKZWajzKzJzAa1tKxMzOx5M7u7FeW2Tu04rwPf1WRmk9u7fgvbHZS2Paqztx1CR8SMDg0mHej/UrF4GSDgd8Clkv5T73p1ltS+QcAESUuKrU0Ioa2ip9S4pgMj+HAqpB7ABGBikZVKpuAzRd/bjnUHAecCH+vMCoUQ6iN6So1rtqSp2RszmwjMA44zs3MkLay2kpmtA6wlaXm1zztD6qn93/bWQgjtF0EpACDpbTN7ADgY6A0sTGMh5wI7AKOBQ/EkhZ8H7gYwsyHAmUB/PKvu08Blkn5d+R1m9nXgDGAb4EV8Eta3qpQbBVwNDJZ0d275usCpwJF4LqIPgPnAZEmXprGXo1Px58wsW3WcpPPSNnoCY1I7twTeBu4Ezpb0bEU9tsRn9T4Az+9zT/r+DjGzbwLDgO2BTYFFwF3AWEnPN7POEOAHwE6pztemOi+tKNfq9oVQRhGUAgBm1gXYNr19o+LjaXj69ouAJjyrLmZ2PPBrfGbnH+JjU0OBiWbWR9J3c9s/FfgFntxwDH658DtAq3LmpIB0G3557nZ8hunlwI7AQXiA+w2wATAcOC3XjsfSNnriaRI+BVwFPIEH2W8CD5nZHpIWpLIfwy8fbpna+CQwEB+P62hG1O/g++wS4E086B8H7GdmO0paVFF+Nzw1+OX4uN9gfGbtHcxsaJZGvS3tC6GsIig1rh5mtgneA9gC+DawM/CgpPkVZZcAQyT9O1uQckRdAlwj6chc2cvM7GLgdDObKOnZdID/IX55cB9J76RtXA081cr6nooHpAskjcl/YGYfAZD0gJk9hgelm6r0OsbjvcDPSHo0t/5kYC4wjg9zXZ0JbA0cK+nqXNsmAKe0ss7N2VHSsoo2zMR7NKOBCyvLA8NzuZayfXwy3nu9ph3tC6GUIig1rnHpX2YFMBM4vkrZCfmAlBwCdAWuTMEtbxZ+wBwCTAL2x3tGv8oCEoCkl8xsWjPfWekoYDF+4F1J1lNoSeoJHoX3fl6uqPMyvOeyf27ZMGAh3jPJ+wkdDEpZQErBdH08Q/Gj+KXMvaqvskryvx/j+3g4cE072hdCKUVQalyTgOvwy3HLgKclvdlM2aerLMuyx97Zwnd8PL32Tq/VekVPrqaemb7AnA7cYLEpsDF+YH69mTL54NYb+Fvl7fGSXjWzDt1qbmb7Ad/HA1C3io83rLLKvMoFuXpk+7at7QuhlCIoNa75kloKKHnvVFnWJb2OJI0xVVGmgfWsvnfivZ1CmNme+JjYM8D3gOfw8bom/DJcex/TKEX7QuioCEqhvbJxpzdaEdyy4NQPv8ssb7tWft/TQD8z6yrpvRbKNZdK+XV8bGyDVgbjZ4G+ZrZWvreUxtI68gzUkcBawBclPZfb7npU7yXBh73S/8nVI9u3bW1fCKUUD8+G9poBvAeMM7NV7kYzs55m1jW9vQPvDXzLzHrkyvTCD9KtMQ0/aI+t8l1dcm+zW6Q3ypdJ407TgP5mdki1LzCzzXJvb8YvP46sKHZWK+vbnCzAdalYPobmf49mZsOaqcdN0K72hVBK0VMK7ZJuUvgGcAUwz8ymAAvwsY0d8RsFtgOel7TYzM4Bfgbcb2a/w298OBHvce3aiq+8GDgQGJu7BLYcf9bH8JsqwAf0AX6SbqJYDjwu6XHgbGBfYIaZzUhl3we2Ar4E/J0P7067EA+Yl5vZ7vjt1YOAvVn1lvm2+D1+u/otZjYpff9Q/Pmj5rY7F5hqZpfj+2swfqPJPfjzSpm2tC+EUoqeUmi3dKv0AOAR4ATgMvzW8i2Ac4DXcmUvwoNQd+AC/OD4M+CXrfyu9/FB/LH4s0M/Sv/6Azfmyt2H9yL64M/1TMcP4Eh6Cz9on4sHswvw8Zev4AfwibntLAY+h/dERqZyPfCAsNLt3G2R6ndw2sb5wHl4L3JgC9udjQf5ffBnxQbgz2UdmL/zsC3tC6GsujQ1NXcJPoQQQqiv6CmFEEIojQhKIYQQSiOCUgghhNKIoBRCCKE0IiiFEEIojQhKIYQQSiOCUgghhNKIoBRCCKE0IiiFEEIojQhKIYQQSuO/EM9XB/zk/xEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_heatmap(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.43      0.42    167434\n",
      "           1       0.43      0.40      0.42    167833\n",
      "           2       0.43      0.38      0.40    167272\n",
      "           3       0.42      0.47      0.44    167732\n",
      "\n",
      "    accuracy                           0.42    670271\n",
      "   macro avg       0.42      0.42      0.42    670271\n",
      "weighted avg       0.42      0.42      0.42    670271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
